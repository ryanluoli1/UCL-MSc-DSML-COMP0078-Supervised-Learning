{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Laplacian Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_50 = pd.read_csv('dtrain13_50.csv')\n",
    "df_100 = pd.read_csv('dtrain13_100.csv')\n",
    "df_200 = pd.read_csv('dtrain13_200.csv')\n",
    "df_400 = pd.read_csv('dtrain13_400.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(X, y, seed=None):\n",
    "    '''\n",
    "    Function to shuffle the data.\n",
    "    X: features\n",
    "    y: labels\n",
    "    '''\n",
    "    if seed:                     \n",
    "        np.random.seed(seed)\n",
    "    idx = np.arange(len(X))          \n",
    "    np.random.shuffle(idx)           \n",
    "    return X[idx], y[idx]\n",
    "\n",
    "def generate_data(data, n_label):\n",
    "    '''\n",
    "    Function to sample n_label labelled samples uniformly at random from the original dataset.\n",
    "    data: the original dataset\n",
    "    '''\n",
    "    #split the data into positive and negative classes\n",
    "    data_pos = data[data['label']==1].copy()\n",
    "    data_neg = data[data['label']==-1].copy()\n",
    "    #split the data into features X and target y\n",
    "    X_pos = data_pos.iloc[:,1:].values.copy()\n",
    "    y_pos = data_pos['label'].values.copy()\n",
    "    X_neg = data_neg.iloc[:,1:].values.copy()\n",
    "    y_neg = data_neg['label'].values.copy()    \n",
    "    #shuffle the data\n",
    "    X_pos, y_pos = shuffle_data(X_pos, y_pos)\n",
    "    X_neg, y_neg = shuffle_data(X_neg, y_neg)\n",
    "    #select the first n_label samples as labelled samples\n",
    "    X_pos_train, y_pos_train = X_pos[:n_label], y_pos[:n_label]\n",
    "    X_pos_test, y_pos_test = X_pos[n_label:], y_pos[n_label:]\n",
    "    X_neg_train, y_neg_train = X_neg[:n_label], y_neg[:n_label]\n",
    "    X_neg_test, y_neg_test = X_neg[n_label:], y_neg[n_label:]\n",
    "    #merge the two classes\n",
    "    X_train = np.append(X_pos_train, X_neg_train, axis=0)\n",
    "    y_train = np.append(y_pos_train, y_neg_train, axis=0)\n",
    "    X_test = np.append(X_pos_test, X_neg_test, axis=0)\n",
    "    y_test = np.append(y_pos_test, y_neg_test, axis=0)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Matrix & Degree Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weight_KNN(X_train, X_test, k=3):\n",
    "    '''\n",
    "    Function to compute the weight matrix using the KNN method.\n",
    "    X_train: training data\n",
    "    X_test: test data  \n",
    "    k: number of nearest neighbours used to make predictions (default=3)\n",
    "    '''\n",
    "    X = np.append(X_train, X_test, axis=0)          #merge the training and test sets\n",
    "    m, n = X.shape[0], X.shape[1]                   #get the sizes of the data matrix X\n",
    "    #distance between a and b: (a-b)^2 = a∙a + b∙b - 2a∙b\n",
    "    A_dots = (X*X).sum(axis=1).reshape((m,1))*np.ones(shape=(1,m))\n",
    "    B_dots = (X*X).sum(axis=1)*np.ones(shape=(m,1))\n",
    "    D = A_dots + B_dots - 2*X.dot(X.T)\n",
    "    idx = np.argsort(D, axis=1)                     #sort the index by the distance\n",
    "    W = np.zeros((m,m))                             #initialize the weight matrix\n",
    "    for i in range(m):                              #for each sample\n",
    "        W[i, idx[i][1:4]] = 1                       #set the nearest 3 neighbours of the ith sample to 1\n",
    "        W[idx[i][1:4], i] = 1                       #do the same for the 3 neigbours \n",
    "    return W\n",
    "\n",
    "def compute_D(W):\n",
    "    '''\n",
    "    Function to compute the Degree Matrix D from the Weight Matrix W.\n",
    "    W: the weight matrix\n",
    "    '''\n",
    "    m = W.shape[0]                  #size of the weight matrix\n",
    "    D = np.zeros((m,m))             #initialize the degree matrix\n",
    "    for i in range(m): \n",
    "        D[i][i] = np.sum(W[i])      #sum of all edges for the ith sample\n",
    "    return D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplacian Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LI(X_train, X_test, y_train, y_test):\n",
    "    '''\n",
    "    Function to train a Laplacian Interpolation algorithm and make predictions on the test set.\n",
    "    X_train: training data\n",
    "    y_train: training labels\n",
    "    X_test: test data\n",
    "    y_test: test labels\n",
    "    '''\n",
    "    W = compute_weight_KNN(X_train, X_test)                   #compute the weight matrix W\n",
    "    D = compute_D(W)                                          #compute the degree matrix D\n",
    "    L = D - W                                                 #compute the graph laplacian L\n",
    "    l, m = len(y_train), len(y_train)+len(y_test)             #get the sizes of labelled and unlabelled data\n",
    "    v = np.zeros(m)                                           #initialize the solution vector\n",
    "    v[:l] = y_train                                           #same labels for the training set\n",
    "    for i in range(l, m):\n",
    "        v[i] = np.sum(W[i]*v) / D[i][i]                       #the harmonic solution\n",
    "    y_pred = np.sign(v)                                       #make predictions based on the sign of the vector v\n",
    "    y_pred_test = y_pred[l:]                                  #obtain the predictions on the test set\n",
    "    error_rate = np.sum(y_pred_test!=y_test)/len(y_test)      #compute the generalization error on the test set\n",
    "    return error_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplacian Kernel Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LKI(X_train, X_test, y_train, y_test):\n",
    "    '''\n",
    "    Function to train a Laplacian Kernel Interpolation algorithm and make predictions on the test set.\n",
    "    X_train: training data\n",
    "    y_train: training labels\n",
    "    X_test: test data\n",
    "    y_test: test labels\n",
    "    '''\n",
    "    W = compute_weight_KNN(X_train, X_test)                    #compute the weight matrix\n",
    "    D = compute_D(W)                                           #compute the degree matrix\n",
    "    L = D - W                                                  #compute the graph laplacian\n",
    "    l, m = len(y_train), len(y_train)+len(y_test)              #get the sizes of labelled and unlabelled data\n",
    "    L_plus = np.linalg.pinv(L)                                 #compute the pseudoinverse of matrix L\n",
    "    K = L_plus[:l,:l]                                          #compute the kernel matrix K\n",
    "    K_plus = np.linalg.pinv(K)                                 #compute the pseudoinverse of matrix K\n",
    "    y_L = y_train                                              #obtain the labels of the labelled samples\n",
    "    alpha = K_plus.dot(y_L)                                    #compute the alpha vector\n",
    "    E = np.zeros((m,m))                                        #initialize the edge matrix E\n",
    "    for i in range(m):\n",
    "        E[i][i+1:] = W[i][i+1:]                                #edge exists when W[i][j]>0 and i  <j\n",
    "    v = np.zeros(m)                                            #initialize the solution vector v\n",
    "    for i in range(l):\n",
    "        v += alpha[i] * E[i].T.dot(L_plus)                     #compute the solution vector v with the labelled data\n",
    "    y_pred = np.sign(v)                                        #make predictions based on the sign of the vector v\n",
    "    y_pred_test = y_pred[l:]                                   #obtain the predictions on the test set\n",
    "    error_rate = np.sum(y_pred_test!=y_test)/len(y_test)       #compute the generalization error on the test set\n",
    "    return error_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data, n_label, LI, LKI, runs=20):\n",
    "    '''\n",
    "    Function to compute the mean empirical generalization error of an algorithm.\n",
    "    data: the entire dataset\n",
    "    n_label: number of labelled samples\n",
    "    algorithm: the algorithm to be evaluated\n",
    "    runs: the number of repeated experiements\n",
    "    '''\n",
    "    errors_LI, errors_LKI = [], []\n",
    "    for run in range(runs):                 \n",
    "        X_train, X_test, y_train, y_test = generate_data(data, n_label)     #randomly sample the training and test sets\n",
    "        error_LI = LI(X_train, X_test, y_train, y_test)                     #make predictions with the LI algorithm\n",
    "        errors_LI.append(error_LI)\n",
    "        error_LKI = LKI(X_train, X_test, y_train, y_test)                   #make predictions with the LKI algorithm\n",
    "        errors_LKI.append(error_LKI)\n",
    "    #compute the mean generalization errors and the standard deviations\n",
    "    LI_mean, LI_std = np.mean(errors_LI), np.std(errors_LI)\n",
    "    LKI_mean, LKI_std = np.mean(errors_LKI), np.std(errors_LKI)\n",
    "    return LI_mean, LI_std, LKI_mean, LKI_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:01<00:00,  3.95it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:04<00:00,  1.14it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:15<00:00,  3.07s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:39<00:00, 19.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────────────────┬───────────────────┬───────────────────┬───────────────────┬───────────────────┬────────────────────┐\n",
      "│  Samples per label  │  L per class = 1  │  L per class = 2  │  L per class = 4  │  L per class = 8  │  L per class = 16  │\n",
      "├─────────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┼────────────────────┤\n",
      "│         50          │   0.8077±0.0534   │   0.6198±0.0903   │   0.4739±0.0863   │   0.2768±0.0770   │   0.1110±0.0356    │\n",
      "│         100         │   0.8500±0.0478   │   0.7342±0.0895   │   0.5880±0.0628   │   0.3663±0.0481   │   0.2140±0.0434    │\n",
      "│         200         │   0.9095±0.0372   │   0.8448±0.0390   │   0.6954±0.0404   │   0.5508±0.0508   │   0.3660±0.0467    │\n",
      "│         400         │   0.9604±0.0133   │   0.8939±0.0296   │   0.8172±0.0318   │   0.6724±0.0486   │   0.5318±0.0393    │\n",
      "└─────────────────────┴───────────────────┴───────────────────┴───────────────────┴───────────────────┴────────────────────┘\n",
      "┌─────────────────────┬───────────────────┬───────────────────┬───────────────────┬───────────────────┬────────────────────┐\n",
      "│  Samples per label  │  L per class = 1  │  L per class = 2  │  L per class = 4  │  L per class = 8  │  L per class = 16  │\n",
      "├─────────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┼────────────────────┤\n",
      "│         50          │   0.1531±0.0907   │   0.0833±0.0755   │   0.0625±0.0331   │   0.0452±0.0128   │   0.0390±0.0163    │\n",
      "│         100         │   0.0399±0.0090   │   0.0462±0.0164   │   0.0323±0.0090   │   0.0364±0.0123   │   0.0280±0.0078    │\n",
      "│         200         │   0.0373±0.0419   │   0.0176±0.0046   │   0.0198±0.0081   │   0.0195±0.0050   │   0.0160±0.0052    │\n",
      "│         400         │   0.0334±0.0550   │   0.0124±0.0024   │   0.0134±0.0047   │   0.0118±0.0021   │   0.0105±0.0018    │\n",
      "└─────────────────────┴───────────────────┴───────────────────┴───────────────────┴───────────────────┴────────────────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "label_nums = [1, 2, 4, 8, 16]\n",
    "data_sizes = [50, 100, 200, 400]\n",
    "data_list = [df_50, df_100, df_200, df_400]\n",
    "\n",
    "results_LI, results_LKI = [], []\n",
    "LI_means, LI_stds, LKI_means, LKI_stds = np.zeros((4,5)), np.zeros((4,5)), np.zeros((4,5)), np.zeros((4,5))\n",
    "\n",
    "for i in range(len(data_list)):                    #for each dataset\n",
    "    \n",
    "    result_LI, result_LKI = [int(data_sizes[i])], [int(data_sizes[i])]\n",
    "    \n",
    "    for j in tqdm(range(len(label_nums))):               #for different numbers of labelled samples\n",
    "        \n",
    "        LI_mean, LI_std, LKI_mean, LKI_std = evaluate(data_list[i], label_nums[j], LI, LKI, runs=20)\n",
    "        LI_means[i][j] = LI_mean\n",
    "        LI_stds[i][j] = LI_std\n",
    "        LKI_means[i][j] = LKI_mean\n",
    "        LKI_stds[i][j] = LKI_std\n",
    "        \n",
    "        result_LI.append(f\"{'{:.4f}'.format(LI_mean)}±{'{:.4f}'.format(LI_std)}\")\n",
    "        result_LKI.append(f\"{'{:.4f}'.format(LKI_mean)}±{'{:.4f}'.format(LKI_std)}\")\n",
    "    \n",
    "    results_LI.append(result_LI)\n",
    "    results_LKI.append(result_LKI)\n",
    "\n",
    "#tabulate the results\n",
    "print(tabulate(results_LI, \n",
    "               headers = [\"Samples per label\", \n",
    "                          \"L per class = 1\", \n",
    "                          \"L per class = 2\",\n",
    "                          \"L per class = 4\",\n",
    "                          \"L per class = 8\",\n",
    "                          \"L per class = 16\"], \n",
    "               tablefmt = \"simple_outline\",\n",
    "               stralign = \"center\",\n",
    "               numalign = \"center\"))\n",
    "print(tabulate(results_LKI, \n",
    "               headers = [\"Samples per label\", \n",
    "                          \"L per class = 1\", \n",
    "                          \"L per class = 2\",\n",
    "                          \"L per class = 4\",\n",
    "                          \"L per class = 8\",\n",
    "                          \"L per class = 16\"], \n",
    "               tablefmt = \"simple_outline\",\n",
    "               stralign = \"center\",\n",
    "               numalign = \"center\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cases when LI outperforms LKI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:01<00:00,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────────────────┬───────────────┬───────────────┬───────────────┬───────────────┬───────────────┐\n",
      "│  Samples per label  │    L = 30     │    L = 35     │    L = 40     │    L = 45     │    L = 48     │\n",
      "├─────────────────────┼───────────────┼───────────────┼───────────────┼───────────────┼───────────────┤\n",
      "│         50          │ 0.0563±0.0386 │ 0.0500±0.0289 │ 0.0275±0.0295 │ 0.0400±0.0663 │ 0.0250±0.0750 │\n",
      "└─────────────────────┴───────────────┴───────────────┴───────────────┴───────────────┴───────────────┘\n",
      "┌─────────────────────┬───────────────┬───────────────┬───────────────┬───────────────┬───────────────┐\n",
      "│  Samples per label  │    L = 30     │    L = 35     │    L = 40     │    L = 45     │    L = 48     │\n",
      "├─────────────────────┼───────────────┼───────────────┼───────────────┼───────────────┼───────────────┤\n",
      "│         50          │ 0.0512±0.0311 │ 0.0567±0.0410 │ 0.0325±0.0327 │ 0.0500±0.0742 │ 0.0375±0.0893 │\n",
      "└─────────────────────┴───────────────┴───────────────┴───────────────┴───────────────┴───────────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "label_nums = [30, 35,  40, 45, 48]\n",
    "data_sizes = [50]\n",
    "data_list = [df_50]\n",
    "\n",
    "results_LI, results_LKI = [], []\n",
    "LI_means, LI_stds, LKI_means, LKI_stds = np.zeros((4,5)), np.zeros((4,5)), np.zeros((4,5)), np.zeros((4,5))\n",
    "\n",
    "for i in range(len(data_list)):                    #for each dataset\n",
    "    \n",
    "    result_LI, result_LKI = [int(data_sizes[i])], [int(data_sizes[i])]\n",
    "    \n",
    "    for j in tqdm(range(len(label_nums))):               #for different numbers of labelled samples\n",
    "        \n",
    "        LI_mean, LI_std, LKI_mean, LKI_std = evaluate(data_list[i], label_nums[j], LI, LKI, runs=20)\n",
    "        LI_means[i][j] = LI_mean\n",
    "        LI_stds[i][j] = LI_std\n",
    "        LKI_means[i][j] = LKI_mean\n",
    "        LKI_stds[i][j] = LKI_std\n",
    "        \n",
    "        result_LI.append(f\"{'{:.4f}'.format(LI_mean)}±{'{:.4f}'.format(LI_std)}\")\n",
    "        result_LKI.append(f\"{'{:.4f}'.format(LKI_mean)}±{'{:.4f}'.format(LKI_std)}\")\n",
    "    \n",
    "    results_LI.append(result_LI)\n",
    "    results_LKI.append(result_LKI)\n",
    "\n",
    "#tabulate the results\n",
    "print(tabulate(results_LI, \n",
    "               headers = [\"Samples per label\", \n",
    "                          \"L = 30\", \n",
    "                          \"L = 35\",\n",
    "                          \"L = 40\",\n",
    "                          \"L = 45\",\n",
    "                          \"L = 48\"], \n",
    "               tablefmt = \"simple_outline\",\n",
    "               stralign = \"center\",\n",
    "               numalign = \"center\"))\n",
    "print(tabulate(results_LKI, \n",
    "               headers = [\"Samples per label\", \n",
    "                          \"L = 30\", \n",
    "                          \"L = 35\",\n",
    "                          \"L = 40\",\n",
    "                          \"L = 45\",\n",
    "                          \"L = 48\"], \n",
    "               tablefmt = \"simple_outline\",\n",
    "               stralign = \"center\",\n",
    "               numalign = \"center\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
